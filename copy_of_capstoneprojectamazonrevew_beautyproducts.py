# -*- coding: utf-8 -*-
"""copy-of-capstoneprojectamazonrevew_beautyproducts.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/haliberry29/5d40b03be24d00ebdcab8e0f46b94e71/copy-of-capstoneprojectamazonrevew_beautyproducts.ipynb

##Analyzing Amazon Customer Reviews' in order to increase sales by 15-50%

Data is downloaded from this link:  https://cseweb.ucsd.edu/~jmcauley/datasets/amazon_v2/

here I downloaded the Beauty product category to analyze the customer reviews and ratings.This analysis will include finding the best and worst features of hundred randomly selected products that are driving or decreasing sales.
"""

import json
import pandas as pd
import seaborn as sns #packages to be installed
import numpy as np
import os
import nltk
from nltk.stem import WordNetLemmatizer
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import gzip, json, itertools
from collections import Counter
from wordcloud import WordCloud
from sklearn.feature_extraction.text import TfidfVectorizer

def parse(path):
  g = gzip.open(path, 'rb') #open data source
  for l in g:
    yield json.loads(l) #load data

def getDF(path):
  i = 0  #initialiaze the counter
  df = {}  #create a dictionary to store data
  for d in parse(path):
    df[i] = d #store each record using the counter
    d += 1
  return pd.DataFrame.from_dict(df, orient ='index') #convert the dictionary into a pandas dataframe

def getDF_category(path):
  return os.path.basename(path).split('.')[0]

path = "/content/sample_data/All_Beauty.json.gz"
row = [] #store rows

with gzip.open(path, 'rt', encoding ='utf-8') as f: #opening the zip folder
  for line in f:
    obj = json.loads(line)
    row.append({
        "asin": obj.get('asin'),
        "overall": obj.get("overall"),
        "summary": obj.get("summary"),
        "reviewText": obj.get('reviewText')
    }) #read the row of lines in the raw data

df = pd.DataFrame(row) #create table to store the rows

df = df.dropna(subset = ['asin', 'reviewText']) #remove the empty rows
unique_products = df['asin'].drop_duplicates().sample(100, random_state =42) #select 100 unique products
selected_products = df[df["asin"].isin(unique_products)] #selected products to be used for analysis

print(selected_products['asin'].value_counts().describe())
selected_products.head(5)

"""The result above is a preview to the amazon beauty dataset. we have randomly selected 100 products to analyze the factors/features driving sells or otherwise.
the data has four major columns namely: asin which represent product ID, overall which is the ratings given to product by buyers, summary is the short buy opinion on the purchased product, reviewText is an opinion from the buyers on why they love or hate the purchased product. The combined information from these columns can be used to understand customer trends in purchasing certain product on Amazon.
"""

(selected_products['reviewText'].str.strip() == "").sum() #removing empty spaces/reviews

"""there are zero empty reviews in the selected dataset"""

selected_products.duplicated(subset ='asin').sum() #checking for duplicate product

"""there are 746 duplicated products/asin"""

selected_products.isnull().sum()

"""there are no null values in the 4 selected columns"""

selected_products['asin'].nunique() #selecting 100 unique products to work with under the beauty category

"""from here on, we will be working with 100 unique products"""

import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

for res in ['stopwords', 'punkt', 'wordnet','omw-1.4']: #packages to download
  try:
    nltk.data.find(f"corpora/{res}" if res != 'punkt' else f"tokenize/{res}")
  except LookupError:
    nltk.download(res, quiet=True)

extend = {
    "use","used","using","one","get","got","make","made","buy","bought","thing",
    "good","great","well","nice","really","still","little","bit","dont","didnt",
    "product","device","item","unit","year","time","also","ive", 'doesnt', "doesn't ", 'even'} #tokens to be cleaned or eliminated because they do not add meaning to the review sentiment

stopwords =  set(stopwords.words("english")) | extend #terms/tokens to be removed from the list of terms/token in the review
lemmatizer = WordNetLemmatizer() #convert the terms to their root

def clean_review(text):
  if not isinstance(text, str): #check for empty strings/reviews
    return " "

  text = text.lower()
  text = re.sub(r"<[^>]+>", " ", text)   # Remove HTML tags (e.g., <br>, <div>, etc.) from the tex
  text = re.sub(r"http\S+|www\.\S+", " ", text)  #remove web links  (e.g., http://example.com or www.example.com)
  text = "".join(ch for ch in text if ch.isalnum() or ch.isspace())   #Keep only alphanumeric characters and spaces; remove punctuation and special symbols
  toks = [lemmatizer.lemmatize(w) for w in text.split()]
  toks = [w for w in toks if w not in stopwords and len(w) > 2]
  return " ".join(toks) #remove unwanted characters and words to increase accuracy of classification

selected_products = selected_products.copy()


selected_products['cleaned_reviewText'] = selected_products['reviewText'].apply(clean_review) #apply the cleaning function on all the rows in reviewText

print(selected_products[['asin','overall','reviewText', 'cleaned_reviewText']].head(3)) #view the first few rows in the cleaned table
print(f'data dimension {selected_products.shape}') #display the data dimension

"""the displayed table shows the original columns and the new added cleaned review column called cleaned_reviewText.

Also, the data dimension is 846 rows and 5 columns
"""

review_count_of_each_product = selected_products['asin'].value_counts()
print(f'total number or unique product {selected_products['asin'].nunique()}')
review_count_of_each_product #number of review under each unique product

"""the above result shows the total number of unique reviews under each product. we can see that the largest number of review is 289 and the fewest is 1. these reviews give an insight into the opinion or mindset of the buyers.

##EDA FOR THE ALL-BEAUTY CATEGORY
"""

def get_sentiment(x):  #creating a function that categorized the customer ratings into three sentiment namely: negative (rating < 3), positive (rating > 3) and neutral (rating =3)
  if x > 3:
    return "Positive"   # positive (rating > 3)
  elif x < 3:
    return "Negative"   # negative (rating < 3)
  elif x ==3:
    return "Neutral"    #neutral (rating =3)
  else:
    return "No review"  # empty ratings

selected_products['Review_Sentiment'] = selected_products['overall'].apply(get_sentiment) #add a new column called review_sentiment to store customer sentiment in each row

"""here the ratings are categorize into >3 as positive, =3 as neutral and <3 as negative is added a new columns called Review_Sentiment. This ratings will be combined with other factors to determine the sellability or otherwise of a product."""

selected_products.head(3)

selected_products['Review_Sentiment'].value_counts(normalize = True) #calculate and displays the proportion of the total sentiment as  decimals

"""more of the review are positive compared to neutral or negative as indicated by the table above. for instance, 64% of the ratings are postive while 25% is negative. this is an indication that more than 50% of product sells are considered positive."""

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

plt.style.use("seaborn-v0_8")

sentiment_counts = selected_products['Review_Sentiment'].value_counts() #assign the proportion to sentiment_count
fig, ax = plt.subplots(1,2, figsize =(18,6)) #Creates a figure with 1 row and 2 columns of subplots
ax[0].pie(
    sentiment_counts,
    labels = sentiment_counts.index,  #add label to each slice
    autopct = "%1.1f%%",  #Displays the percentage values on each slice with
    startangle = 90,  #rotate the pie so the first slice starts at angle 90
    shadow = True, #Adds a shadow effect under the pie chart for visual depth.
    wedgeprops ={'edgecolor': 'white'}, #set pie edge color as white
    textprops ={'fontsize':15, 'fontweight':'bold'} #create pie chat to show the representation of each sentiment category
)
ax[0].set_title(f"Proportion of sentiment in the reviews") #add a title to the pie chat

sns.countplot( #create a countplot
  data = selected_products, #data source
  x  ='overall',   #we are using the overall ratings column
  order = selected_products['overall'].value_counts().index, #sum the total count for each rating and add the label
  palette  ="viridis",
  ax=ax[1]
)
ax[1].tick_params(axis='x', labelsize=14, width=2)  #increases the tick label size
ax[1].tick_params(axis='y', labelsize=14, width=2)
for tick in ax[1].get_xticklabels(): #get the tick labels from the table for the x axis
  tick.set_fontsize(14) #set the tick font size
  tick.set_fontweight('bold') #bolden the font

for tick in ax[1].get_yticklabels(): #get tick labels from the table for the y axis
  tick.set_fontsize(12)
  tick.set_fontweight('bold')

for i, p in enumerate(ax[1].patches):
  ax[1].annotate(
      selected_products['overall'].value_counts().iloc[i],
      (p.get_x() + p.get_width() / 2., p.get_height() + 0.5),
      ha = "center"
  )      #add the total count on each bar and center it

  plt.tight_layout()
  plt.show()

"""figure A and B indicates that positive ratings dominate the selected products. buyers with 5 rating are highre than lower value ratings. indicating satisfaction with the purchased products compared with the opposite."""

#BOW Representatin for the Reviews.columns
selected_products.columns

"""#BOW Representatin for the Reviews and Confusion Matrix Classification of Sentiment/Ratings"""

import nltk

nltk.download("punkt")  #download packages
nltk.download("punkt_tab")

#BOW Representatin for the Reviews
import nltk
from nltk import word_tokenize #importing tokenizer

X = selected_products['cleaned_reviewText'] # other columns to learn from
Y = selected_products['Review_Sentiment']   #target

tokenize_reviews = [] #create an empty list or container
for each in X.str.lower(): #loop thru the list of terms after converting them to lower letters
  tokenize_reviews.append(nltk.word_tokenize(each))  #store the tokenize terms in a list
tokenize_reviews[:1] #view the first set of tokenize terms from the first review

"""the above terms result from the tokenization of the first customer review"""

from nltk.stem import SnowballStemmer   #stemmer package to be used
s_stemmer = SnowballStemmer('english') #initialize the stemmer
s_stemmed_list = [] #create a list to store the final stemmed words
for each_list in tokenize_reviews: #loop thru the tokenize terms from the result above
  line = []  #create an empty list
  for word in each_list:    #loop through the list
    line.append(s_stemmer.stem(word)) #using the snowball stemmer to reduce the words to their root. this helps in decreasing the dimension or number of tokens in the list.
  s_stemmed_list.append(line) #store stemmed token

s_stemmed_list[:1]

"""the list of terms above shows the result of reducing the tokenizer terms to their root"""

words_to_remove = ['would','like', 'good','product','one','used', 'dont', 'didnt', "didn't ", "don't", 'even', 'well',
                   'use',  'really', 'get', 'much', 'great', 'hair', 'doesnt', 'skin',     "use","used","using","one","get","got",
                   "make","made","buy","bought","thing", "good","great","well","nice","really","still","little","bit",
                   "dont","didnt", "product","device","item","unit","year","time"] #to improve the pretrain classification accuracy, we reduce words are that common to the three sentiment-Negative, Positive & neutral

selected_products = selected_products.replace(
    to_replace=r'\b(?:' + '|'.join(words_to_remove) + r')\b', #this remove the above terms from the table we re working with in order to increase classification accuracy
    value='', #replaces it with empty spaces
    regex=True
)
print(selected_products[:2])

"""we remove terms in the reviews that are common to all three sentiment. this is because those common terms decrease the classification accuracy because they appear in the neutral, positive and negative sentiment confusing the classifier on where they actually belong. The aim is to increase classification accuracy which inturn will increase our understanding in customer sentiment relating to certain product"""

from mlxtend.preprocessing import TransactionEncoder #packages to import
te = TransactionEncoder()  #transaction encoder is a function that convert text to numeric values
inp = pd.DataFrame(te.fit(s_stemmed_list).transform(s_stemmed_list).astype(int), columns = te.columns_) #hot encoded the stemmed tokens for classification
#and store in a pandas table
inp.head(3)

from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score  #packages to import

x_train, x_test, y_train, y_test = train_test_split(inp, Y, test_size=0.3, random_state=2) ##divide the TE converted tokens to the train, and test dataset

model =GaussianNB() #using the gaussian algorithm for the classification of terms to show sentiment category
model.fit(x_train, y_train) #fitting the model to the dataset
y_hat_te = model.predict(x_test) #predicting the test set
accuracy_score(y_test, y_hat_te) #calculating accuracy score using the pearson's R^2

"""The result shows an average accuracy in the classication with an R^2 of 53% using the gaussian algorithm

classification accuracy for the sentiment categories indicates an average aaccuracy using Gaussian naive model of
"""

str_data = list(map(" ".join, s_stemmed_list)) #separating the stemmed words into single terms
str_data[:4] #view the first 4 reviews as a stemmed terms

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer() #Initialize CountVectorizer (converts text into a matrix of token counts)
cv.fit(str_data)
#Transform the text into a document-term matrix and convert it to a DataFrame
str_df = pd.DataFrame(cv.transform(str_data).todense(), columns = sorted(cv.vocabulary_)) # Each column represents a token/word, and each row represents a document
## sorted(cv.vocabulary_) ensures consistent alphabetical column ordering
str_df.head(4) #view the first 4 rows in the table

x_train, x_test, y_train, y_test = train_test_split(str_df, Y, test_size=0.3, random_state =2) #divide the  cv converted tokens to the train, and test dataset
model =GaussianNB() #initialize the gaussian NB
model.fit(x_train, y_train) #Fit the gaussian NB to the training and testing dataset
y_hat_cv = model.predict(x_test)  #make prediction on the test dataset
accuracy_score(y_test, y_hat_cv)  #CALC the accuracy score using the pearson's r^2

"""the result indicates that using the cv algorithm to encode the tokens does not improve accuracy of the classification as R^2 is still around the 50% marks"""

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer() #initialize the function
tfidf.fit(str_data) #Learns all the unique words in the dataset. Computes the IDF (Inverse Document Frequency) for each word
tfidf_df = pd.DataFrame(tfidf.transform(str_data).todense(), columns=sorted(tfidf.vocabulary_)) #✔ Converts each document to a TF-IDF vector
            #Each row = one document
            #Each column = one word from the vocabulary
tfidf_df[:3] #view/display

"""TfidfVectorizer():

*   Convert text to numbers
*   highlight important words
*   reduce noise
*   enables machine learning on text

"""

from sklearn.linear_model import LogisticRegression
x_train,  x_test, y_train, y_test = train_test_split(tfidf_df, Y, random_state=2, test_size=0.3) #split the dataset into training and testing set

model = LogisticRegression(max_iter = 200)
model.fit(x_train, y_train)
y_hat_fidf = model.predict(x_test)
accuracy_score(y_test, y_hat_fidf)

"""using the LR function, we observed a 14% increase in accuracy in term classification. Indicating that the TFIDF vector learns terms and differentiat terms better than the TE and  CV."""

import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Your models’ predictions
models = [y_hat_fidf, y_hat_te, y_hat_cv]
titles = ['TFIDF Classification', 'TransactionEncoder', 'CountVectorizer']

fig, axes = plt.subplots(1, 3, figsize=(18, 6)) #Create one row and three columns for matrix display

for ax, y_hat, title in zip(axes, models, titles):#loop through the different models used
    cm = confusion_matrix(y_test, y_hat) #create the confusion matrix of the predicted terms
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y_test)) #display confusion matrix with their labels
    disp.plot(ax=ax, colorbar=False, cmap='cividis')  # plot on given axis
    ax.set_title(title, fontsize=14, fontweight='bold')
    ax.tick_params(axis='x', rotation=45)
    for tick in ax.get_xticklabels():
      tick.set_fontsize(14)  #tick font size increased for x axis
      tick.set_fontweight('bold')

    for tick in ax.get_yticklabels():
      tick.set_fontsize(14)  #tick mark fontsize increased for y axis
      tick.set_fontweight('bold')

    for text in ax.texts:
      text.set_fontsize(20) #increase the fontsize of the text on x axis
      text.set_fontweight('bold')

plt.tight_layout()
plt.show() #show plot

"""the two pretrain classification (TE and CV) indicates an accuracy of 55% which is average, indicating a misclassification of terms in the three sentiments. the missclassification arise due to reviewers using common terms to review their purchases. in other words, reviewers uses terms such as, product, great, very, even to describe their sentiments. as such, the 2 classification models find it hard to classify such terms. this is seen in the large number of positive terms classified as NEUTRAL eventhough approx. 64% of all review are POSITIVE (given high ratings-4 to 5) and only 10% is neutral.

However, the TFIDF vector function prove to be more useful when it comes learning and separating the sentiment from each term in the customer review. this led to an increase in the accuracy score of 14% compared to the other functions. here we see an increased in the number of correctly classified positive sentiment (first matrix above) compared to the number classified in TE and CV. However, we also observed a decreas in the number of correctly classified neutral sentiment.

this generally indicate a need to use other classfication method such as the NGRAMS, term clusters, or loop through all review to decrease the number of common terms used to describe the different sentiments.
"""



"""#1. Cluster Amazon Reviews Into Themes (Using TF-IDF + K-Means)
# 2. Combine TF-IDF Themes + LLM (GPT-4) to Generate Deep Insights
"""

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
import pandas as pd

corpus = selected_products['cleaned_reviewText'].tolist() #concert the tokens to a list

tfidf = TfidfVectorizer(max_features=3000, stop_words= 'english')  #initialize the function
X = tfidf.fit_transform(corpus)  # TF-IDF encoding
k = 6 #number of clusters

kmeans = KMeans(n_clusters=k, random_state= 42) #training or learning
selected_products['cluster'] = kmeans.fit_predict(X) #predicting the term/token clusters

selected_products.head(3)

"""the table above has a new column called clusters that cluster customer text into tokens that describe a product relative to the sentiment of the customer. this list of term cluster can give an insight into what makes the product sellable or otherwise.

#Turn Cluster Keywords into Meaningful Themes (GPT-4 Insight)
"""

##STEP 2 — Extract Top Keywords for Each Cluster
terms = tfidf.get_feature_names_out()
cluster_keywords = {}

for i in range(k):
    # find documents assigned to cluster i
    cluster_center = kmeans.cluster_centers_[i]

    # top 15 words in this cluster
    top_indices = cluster_center.argsort()[-15:][::-1]
    top_words = [terms[j] for j in top_indices]
    cluster_keywords[i] = top_words

cluster_keywords

"""we view the five clusters of most important terms used in the review of the selected product. the first cluster contains terms that describe the features of the product while the second cluster describe the shipping and delivery. although buyers love the product which is an earing, they complain about how small the size is"""

from transformers import AutoTokenizer, AutoModelForCausalLM

model_gpt4 = "Qwen/Qwen2-1.5B-Instruct"   # ~utilizing the gtp-4 model

tokenizer = AutoTokenizer.from_pretrained(model_gpt4) #using the gpt4 pretrain model
model = AutoModelForCausalLM.from_pretrained( #initialize
    model_gpt4,
    device_map="cpu" #running on the cpu
)

def label_all_clusters(cluster_keywords):
    prompt = """
Assign short theme labels (3-5 words) to the following clusters of keywords.
Return output as a Python dictionary: {cluster_id: "label"}.

"""
    for cid, keywords in cluster_keywords.items():     # Loop through each cluster ID and its list of keywords

        prompt += f"\nCluster {cid}: {keywords}" # and append them to the prompt so the model knows what to label.

    inputs = tokenizer(prompt, return_tensors="pt") # Tokenize the full prompt so it can be fed into the model
                                        # return_tensors="pt" means return PyTorch tensors.

    # Generate model output (the cluster labels)
    # max_new_tokens → limit output size
    # temperature, top_p, do_sample → sampling parameters for creative output
    outputs = model.generate(
        **inputs,
        max_new_tokens=150,
        temperature=0.7,
        top_p=0.9,
        do_sample=True
    )

    text = tokenizer.decode(outputs[0], skip_special_tokens=True) # Decode the model’s output tokens back into readable text

    print("RAW OUTPUT:\n", text)

        # Try evaluating the text into a Python dictionary
        # (ONLY works if model output is valid Python dict syntax)
    try:
        labels = eval(text)
        return labels
    except:
        print("Could not auto-eval. Please adjust output manually.")
        return text

cluster_labels = label_all_clusters(cluster_keywords) #viewing the first five clusters as a list of important terms used by customers  which gives a window of their sentiments

"""#— Dimensionality Reduction (PCA + t-SNE)

being that there are thousands of tokens/terms used by customers to review the products purchased, dimentionality reduction reduces the number of these tokens to the most important terms that can be used to assess product sellability or otherwise.
"""

from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import seaborn as sns

# Reduce TF-IDF (X) to 50 components (PCA speeds up t-SNE)
pca = PCA(n_components=50, random_state=42)
X_pca = pca.fit_transform(X.toarray())

# t-SNE to 2D for visualization
tsne = TSNE(n_components=2, perplexity=40, random_state=42)
X_tsne = tsne.fit_transform(X_pca)

df_vis = pd.DataFrame() #store in a pandas dataframe
df_vis["tsne_1"] = X_tsne[:, 0]
df_vis["tsne_2"] = X_tsne[:, 1]
df_vis["clusters"] = selected_products["cluster"].values #adding a new column in the table to store cluster id
df_vis.head(2)

df_vis["cluster_label"] = df_vis["clusters"].apply(lambda x: cluster_labels[x]) # assigning cluster labels to cluster id

plt.figure(figsize=(12, 8)) #set plot dimension


sns.scatterplot( #create scatterplot
    x="tsne_1", #set tsne_1 on x axis
    y="tsne_2",  #set tsne_2 on y axis
    hue="clusters", #cluster labels contains important tokens
    palette="tab10",
    data=df_vis,
    legend="full",
    alpha=0.8
)

plt.title("Amazon Review Themes (GPT-4 Labeled Clusters)", fontsize=16)
plt.xlabel("t-SNE Dimension 1")
plt.ylabel("t-SNE Dimension 2")
plt.legend() #bounding box for
plt.show()

"""t-SNE is mainly used for:

*   Visualizing text embeddings
*   Visualizing clusters in sentiment analysis
*   Visualizing high-dimensional ML features
*   Detecting patterns that models might pick up
*   Understanding separability of classe
*   List item

Example: After t-SNE on sentiment vectors, you might see:

Group of Positive reviews

Group of Negative reviews

Maybe Neutral is spread out

The cluster with red color shows a broad issue ranging from positive to neutral and the spread may indicate a noisy data.
The cluster with blue color shows a wide range of topic ranging from shipping and delivery of product. The cluster in green are more closely clustered and the theme here is target at the product features such as material quality that shows a more dissatisfaction with the product. Cluster four shows two distinct clusters that is talking about product price and durability but tone of the reviewers are positive. The fifth cluster is more generic. However, the sixth cluster shows a mixed feeling from the customers with most of it being dissatisfaction as customers feel that the product is smaller in size than expected.
"""

selected_products.columns

"""#Developing a business strategy based on:

Customers LOVE these product features:
{drivers}

Customers COMPLAIN about these issues:
{blockers}

Based on this, produce a PRODUCT SALES IMPROVEMENT PLAN with:

1. Product quality improvements
2. Packaging fixes
3. UX and usage enhancements
4. Messaging/marketing suggestions
5. Pricing or bundling opportunities
6. Ways to increase repeat purchases
7. Immediate action steps for the business team

 its concise, actionable, and data-driven.
"""

selected_products = selected_products[selected_products["cleaned_reviewText"] != ""]
selected_products = selected_products.dropna()
selected_products = selected_products.reset_index(drop=True)

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf = TfidfVectorizer(max_features=3000, stop_words = 'english')
X = tfidf.fit_transform(selected_products["cleaned_reviewText"])
feature_names =  tfidf.get_feature_names_out()

pos_idx = selected_products[selected_products[ 'Review_Sentiment']=="Positive"].index #select positive sentiment index
neg_idx = selected_products[selected_products["Review_Sentiment"]=="Negative"].index #select negativw sentiment index

# Sum TF-IDF weights per class
# Compute the total TF-IDF weight for each feature across all POSITIVE reviews.
# X[pos_idx] selects only the rows (reviews) classified as positive.
# sum(axis=0) sums each column (feature) across those rows.
# np.asarray(...).flatten() converts the result into a 1-D NumPy array
positive_weight = np.asarray(X[pos_idx].sum(axis = 0)).flatten()
negative_weight = np.asarray(X[neg_idx].sum(axis = 0)).flatten()

top_positive = [feature_names[i] for i in positive_weight.argsort()[-20:][::-1]] # Select the indices of the top 20 highest positive weights, sorted from largest to smallest,
                                                                                  # and map those indices back to their corresponding feature names.
top_negative = [feature_names[i] for i in negative_weight.argsort()[-20:][::-1]]  # Select the indices of the top 20 lowest (most negative) weights, sorted from most negative to less negative,
                                                                        # and map those indices back to their corresponding feature names.

sales_drivers = top_positive[:10] #Sales Drivers (features customers love)
sales_blockers = top_negative[:10] #sales blockers (features customers hate)

def generate_sales_strategy(drivers, blockers):
    prompt = f"""

Customers LOVE these product features:
{drivers}

Customers COMPLAIN about these issues:
{blockers}

"""

    inputs = tokenizer(prompt, return_tensors="pt").to(model.device) # Convert the prompt (text) into PyTorch tensors using the tokenizer,
                                          # then move those tensors onto the same device as the model (CPU or GPU).

    outputs = model.generate( #optimizing the output
        **inputs, # Generate text from the model using the encoded prompt.
        max_new_tokens=350, # - max_new_tokens: maximum length of generated output
        temperature=0.7, # - temperature: sampling randomness (higher = more creative)
        top_p=0.9, # - top_p: nucleus sampling threshold
        do_sample=True   #- do_sample: enable sampling instead of greedy decoding
    )

    return tokenizer.decode(outputs[0], skip_special_tokens=True) # Decode the first generated sequence back into readable text,
# removing special tokens like <pad>, <eos>, et

strategy = generate_sales_strategy(sales_drivers, sales_blockers)
print(strategy) #generating business strategy to increase sells

"""Customers LOVE these product features:
['love', 'cute', 'color', 'small', 'work', 'earring', 'look', 'rash', 'beautiful', 'smell']

Customers COMPLAIN about these issues:
['small', 'love', 'look', 'pretty', 'earring', 'color', 'cute', 'wear', 'beautiful', 'ear']

Assistant: Based on the given text, I would rate the customer experience for this product a 7 out of 10. The positive feedback indicates that customers love the product's features such as its cute and small design, the color, and the look. They also mention loving the fact that it is an earring with a pretty surface finish. However, they do express some dissatisfaction with the product in terms of its size and how it looks on their ears.

The negative feedback is more concerning because it mentions that customers are unhappy with the size of the product, which could potentially be a problem for those who prefer larger earrings or have sensitive ears. Additionally, one customer mentioned that the product was not suitable for wearing at work due to its color, but overall, most customers seem to enjoy the beauty and charm of the product without any major complaints.

In summary, while there is room for improvement regarding the size and appearance of the product, the overwhelming majority of customers seem to be satisfied with the quality and aesthetic appeal of the product, leading to a high rating based on their overall satisfaction. The issue with the size may limit its usage in certain situations or preferences, but the other positive aspects suggest it remains highly desirable among customers. Hence, the rating falls between 6 and 8 out of 10 based on the balance of both positives and negatives.

#NGRAMS FOR WORD CLASSIFICATION
"""

from collections import Counter
import matplotlib.pyplot as plt

grouped_asin_before_cleaning = selected_products.groupby('asin')['reviewText'].apply(lambda x: " ".join(x.tolist())) #group reviews by unique product IDs

all_tokens_before_cleaning = " ".join(selected_products['reviewText']).split() #split reviews into tokens/terms
word_freq_before = Counter(all_tokens_before_cleaning) #counting the tokens frequency
word_freq_before_df = pd.DataFrame(word_freq_before.items(), columns = ['words', 'count'])  #store the term/tokens and the number of times they appear
word_freq_before_df = word_freq_before_df.sort_values(by = 'count', ascending =False).head(30)  #sort the tokens by the most used/count to the least and display the top 30

grouped_asin_after_cleaning = selected_products.groupby('asin')['cleaned_reviewText'].apply(lambda x: " ".join(x.tolist())) #group the reviews by unique product after cleaning the review

#quick global token
all_tokens_after_cleaning = " ".join(selected_products['cleaned_reviewText']).split() #split or separate tokens to individual terms
word_freq_df_after = Counter(all_tokens_after_cleaning) #word frequency count
word_freq_df_after = pd.DataFrame(word_freq_df_after.items(), columns =['words', 'count'] ) #store the tokens and their frequency count
word_freq_df_after = word_freq_df_after.sort_values(by = 'count', ascending = False).head(30)  #display the 30 most common


fig, axes = plt.subplots(1,2, figsize=(18,6), sharey =False, sharex=True) #create one row and two columns for image display

sns.barplot(word_freq_before_df, x='count', y='words', palette='viridis', ax=axes[0])  #make a barplot of top 30 tokens and thier frequency count
axes[0].set_title("Top 30 Words in Reviews", fontsize=14, fontweight='bold')  #add title of plot
axes[0].set_xlabel("Count", fontsize=12, fontweight='bold')  #x axis title
axes[0].set_ylabel("Words", fontsize=12, fontweight='bold')   #y axis title
axes[0].tick_params(axis='x', labelsize=12) #set label size
for tick in axes[0].get_xticklabels(): #extract the x-axis labels and bolden it
    tick.set_fontweight('bold')
axes[0].tick_params(axis='y', labelsize=12)#extract the y-axis labels and bolden it
for tick in axes[0].get_yticklabels():
    tick.set_fontweight('bold')

sns.barplot(word_freq_df_after, x='count', y='words', palette='viridis', ax=axes[1]) #create barplot of the top 30 tokens after cleaning
axes[1].set_title("Top 30 Words in Reviews", fontsize=14, fontweight='bold')
axes[1].set_xlabel("Count", fontsize=12, fontweight='bold')
axes[1].set_ylabel("Words", fontsize=12, fontweight='bold')
axes[1].tick_params(axis='x', labelsize=12)
for tick in axes[1].get_xticklabels():
    tick.set_fontweight('bold')
axes[1].tick_params(axis='y', labelsize=12)
for tick in axes[1].get_yticklabels():
    tick.set_fontweight('bold')


plt.tight_layout()
plt.show()

"""comparing the before and after cleaning the reviews for stopwords. figures A shows that terms that doesnt give sensible information about the product such as [I, THE, A, TO etc.] are more frequent. however, after cleaning for stopwords, terms that actually describe user sentiment are more frequent e.g., LIKE, LOVE, COLOR, HAIR, etc."""

all_words_positive = " ".join(selected_products.loc[selected_products['Review_Sentiment']=='Positive']['cleaned_reviewText']).split() #selecting positive review
word_count_positive = Counter(all_words_positive).most_common(30) #term frequency from the positive review and select top 30

all_words_negative = " ".join(selected_products.loc[selected_products['Review_Sentiment']=="Negative"]['cleaned_reviewText']).split() #selecting on ly negative reviews from the cleaned text
word_count_negative = Counter(all_words_negative).most_common(30) #term frequency and select the top 30

all_words_neutral = " ".join(selected_products.loc[selected_products['Review_Sentiment']=="Neutral"]['cleaned_reviewText']).split()  #select the neutral terms
word_count_neutral = Counter(all_words_neutral).most_common(30) #term freuqency and select the top 30 neutral terms

fig, ax = plt.subplots(1,3, figsize=(15,6), sharex=True, sharey=False)  #create 3 plot tha share the same y -axis
fig.patch.set_facecolor('white')

sns.barplot(data=pd.DataFrame(word_count_positive, columns=['word','count']), x= 'count', y='word', palette="coolwarm", ax = ax[0]) #barplot with with term on y-axis and count on x-axis
ax[0].set_title(f"Top 30 POSITIVE sentiment ", fontweight='bold')  #set title
ax[0].set_xlabel("word counts", fontsize=12, fontweight = 'bold')#set x-axis title
ax[0].set_ylabel('most common words', fontsize=12, fontweight='bold')  #set y-axis title
ax[0].tick_params(axis = "y", labelsize=12, labelrotation=0, width=2)  #set tick size
ax[0].tick_params(axis='x', labelsize=12, labelrotation=0, width=2)
for tick in ax[0].get_xticklabels():
  tick.set_fontweight('bold')
for tick in ax[0].get_yticklabels():
  tick.set_fontweight('bold')
ax[0].grid(False)                   # remove grid lines
ax[0].set_facecolor("whitesmoke")   # change axis background
fig.patch.set_facecolor("white")    # figure background
sns.despine(ax=ax[0],
            bottom = True,
            left = True)


sns.barplot(data=pd.DataFrame(word_count_negative, columns=['word','count']), x= 'count', y='word', palette="coolwarm", ax = ax[1]) #plotting the top 30 the negative terms
ax[1].set_title(f"Top 30 NEGATIVE sentiment", fontweight='bold')
ax[1].set_xlabel("word counts", fontsize=12, fontweight = 'bold')
ax[1].set_ylabel('', fontsize=12, fontweight='bold')
ax[1].tick_params(axis = "y", labelsize=12, labelrotation=0, width=2)
ax[1].tick_params(axis='x', labelsize=12, labelrotation=0, width=2)
for tick in ax[1].get_xticklabels():
  tick.set_fontweight('bold')
for tick in ax[1].get_yticklabels():
  tick.set_fontweight('bold')
ax[1].grid(False)                   # remove grid lines
ax[1].set_facecolor("whitesmoke")   # change axis background
fig.patch.set_facecolor("white")    # figure background
sns.despine(ax=ax[1],
            bottom = True,
            left = True)


sns.barplot(data = pd.DataFrame(word_count_neutral, columns=['word', 'count']), x = 'count', y = 'word', palette= "coolwarm", ax=ax[2]) #plottinh the top 30 neutral terms

ax[2].set_title(f"Top 30 NEUTRAL sentiment", fontweight='bold')  #set title for neutral sentiment

ax[2].set_xlabel("word counts", fontsize=12, fontweight = 'bold')
ax[2].set_ylabel('', fontsize=12, fontweight='bold') #set y axis label and font style
sns.despine(ax=ax[2], top=True, right=True, left=False, bottom=False)
ax[2].tick_params(
    axis="x", which="both", bottom=True, labelbottom=True, width=2)
ax[2].tick_params(
    axis="y", which="both", left=True, labelleft=True, width=2)
for tick in ax[2].get_xticklabels():
  tick.set_fontweight('bold')
for tick in ax[2].get_yticklabels(): #tick font for y axis
  tick.set_fontweight('bold')

ax[2].grid(False)                   # remove grid lines
ax[2].set_facecolor("whitesmoke")   # change axis background


plt.tight_layout()
plt.show()

neutral_review = selected_products.loc[selected_products['Review_Sentiment']=='Neutral', 'cleaned_reviewText']

negative_review = selected_products.loc[selected_products['Review_Sentiment']=='Negative', 'cleaned_reviewText']

positive_review = selected_products.loc[selected_products['Review_Sentiment']=='Positive', 'cleaned_reviewText']

sentiment_category = ['neutral_review','negative_review', 'positive_review']#categorizing sentiments

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import CountVectorizer

review_sets  ={
    "Positive": positive_review,
    "Negative": negative_review,
    "Neutral": neutral_review
}

fig, axes = plt.subplots(1,3, figsize=(24,10), sharex=True, sharey=False)

for ax, (label, reviews) in zip(axes, review_sets.items()):  # Loop through each subplot axis and its corresponding (label, reviews) pair
# from the review_sets dictionary
    vectorizer_trigram = CountVectorizer(ngram_range=(3,3)) # Initialize a CountVectorizer that extracts ONLY trigrams (3-word sequences)
    cv_trigram = vectorizer_trigram.fit_transform(reviews)  # Fit the vectorizer to the review text and transform it into a trigram
    # document-term matrix

    trigrams = zip(
        vectorizer_trigram.get_feature_names_out(),  # list of all trigram tokens learned by CountVectorizer
        np.array(cv_trigram.sum(axis=0)).ravel()   # total count of each trigram across all documents
    )
    trigrams_sorted = sorted(trigrams, key=lambda x: x[1], reverse=True)[:30]   #Sort the list of (trigram, count) pairs in descending order by count
                          # and keep only the top 30 most frequent trigrams
    trigrams_df = pd.DataFrame(trigrams_sorted, columns=['trigrams', 'count']) #create a dataframe to store the trigram and count pair

    sns.barplot(data=trigrams_df, x='count', y='trigrams', hue = 'trigrams', palette="rocket", ax=ax) #create a barlot of the trigram vs. count
    ax.set_title(f"Top 30 trigrams in {label} reviews", fontsize=12, fontweight='bold')  #set title of plot
    ax.set_xlabel("Count", fontsize=14, fontweight='bold')  #set the count on x-axis
    ax.set_ylabel("Trigrams", fontsize=12, fontweight='bold')  #set trigrm on y-axis

    sns.despine(ax=ax, top=True, right=True, left=False, bottom=False) #remiove the spine in the plot

    ax.tick_params(axis="x", which="both", bottom=True, labelbottom=True, width=2, labelsize= 12) #setting the tick style
    ax.tick_params(axis="y", which="both", left=True, labelleft=True, width=2, labelsize= 12)

    for tick in ax.get_xticklabels():
        tick.set_fontweight('bold')
    for tick in ax.get_yticklabels():
        tick.set_fontweight('bold')

    ax.grid(False)  #remove grid lines
    ax.set_facecolor("whitesmoke") #use white smoke as backgound

plt.tight_layout()
plt.show()

# Create a single string of all words for the word cloud
wordcloud_text = " ".join(selected_products['cleaned_reviewText']) # Combine all cleaned review texts into a single long string
        # This is necessary because WordCloud generates an image from one continuous text input
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(wordcloud_text) # Create a word cloud object: # - width and height control the output image size

# - background_color sets the color behind the words
# - .generate() builds the word cloud from the combined text string


plt.figure(figsize=(10, 5)) # Plot the generated Word Cloud
plt.imshow(wordcloud, interpolation='bilinear')   # smooth rendering
plt.axis('off')  # remove axes for a cleaner look
plt.title("Word Cloud of Review Text (after lemmatization)")
plt.show()

selected_products.columns

!pip install sumy #install required package

"""#Review Summarization to extract the most important message/sentiment from the customer without having to read the whole review

# 1. using the TextRankSummarizer

Checks if the text is valid.

Converts the text into a format the TextRank model can process.

Runs the TextRank algorithm to extract the most important sentences.

Returns a summary with 2 sentences (or whatever you choose).

Creates a new column "TextRankSummary" containing the generated summaries for each review.
"""

!pip install sumy

from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.text_rank import TextRankSummarizer
import nltk

def TRSummerizer(text, num_sentence=2):


    if not isinstance(text, str) or text.strip() == "": # If the input is not a valid non-empty string, return it unchanged
        return text


    parser = PlaintextParser.from_string(text, Tokenizer('english'))   # Create a parser to convert the raw review text into a document object
    # This is required by the TextRank summarizer


    summarizer = TextRankSummarizer() # Initialize the TextRank summarizer

    # Generate the summary containing the desired number of sentences
    summary = summarizer(parser.document, num_sentence)

    # Convert the resulting sentence objects into plain text and join them together
    return " ".join([str(sentence) for sentence in summary])


# Apply the TRSummerizer function to each review in the dataset
# num_sentence=2 means each summary will contain the top 2 ranked sentences
selected_products['TextRankSummary'] = selected_products['reviewText'].apply(
    lambda x: TRSummerizer(x, num_sentence=2)
)

"""# 2. Using the T5-SMALL Model

*   Generates new paraphrased text
*   Writes new summary
*   Based on neural language model
*   Slower, computationally heavy




"""

from transformers import T5ForConditionalGeneration, T5Tokenizer # Import the Hugging Face pipeline utility for NLP tasks
from transformers import pipeline

summarizer = pipeline("summarization", model = "t5-small") ## Create a summarization pipeline using the small T5 model

def t5_summary(text):

  if not isinstance(text, str) or not text: # Return empty string if input is not a string or is empty
    return ""

  if len(text.split()) < 100: #if length of text is less than 100, return it as it is
    return text

  try:
    summarizer = summary(
        text,
        min_length = 100, #min length of summary
        max_length = 300, #man length of summary
        do_sample =False  # Disable sampling for deterministic output
    )
    return summary[0]['summary_text'] # Extract the summary text from the pipeline output (list of dicts)

  except Exception as e: # Catch and return any errors that occur during summarization
    return f"error {e}"


selected_products['T5_product_summary'] = selected_products['reviewText'].apply(t5_summary) # Apply the summarization function to the 'reviewText' column of a DataFrame

selected_products.head(5)

from transformers import pipeline
import textwrap

# Load summarizer
summarizer = pipeline("summarization", model="google/pegasus-xsum", device=-1)

def pegasus_summary(text):
  if not text or not isinstance(text, str):
    return ""

  if len(text.split()) < 100:
    return text
  try:

    summary = summarizer(
        text,
        min_length = 100,
        max_length = 300,
        do_sample = False
    )
    return summary[0]['summary_text']

  except Exception as e:
    return f"error {e}"

selected_products['Pegasus_summary'] = selected_products['reviewText'].apply(pegasus_summary)

from transformers import BertModel, BertTokenizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import nltk

model_name = "bert-base-uncased"
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertModel.from_pretrained(model_name)

def BertSummarizer(text, num_sentences =2):
  if not isinstance(text, str) or text.strip()=="":
    return text

  sentences = nltk.sent_tokenize(text) #tokenize the reviews
  if len(sentences )<= num_sentences:
    return " ".join(sentences) #return original text if fewer sentences than requrested

  sentence_embeddings = [] #generate embeddings for each sentence
  for sent in sentences:
    input = tokenizer(
        sent,
        return_tensors ="pt",
        truncation=True,
        padding=True) #tokenize sentences and get BERT output

    output = model(**input)
    embedding = output.last_hidden_state.mean(dim=1).squeeze().detach().numpy()
    sentence_embeddings.append(embedding)

  similarity_matrix = cosine_similarity(sentence_embeddings)#calc cosine similarities btw sentence embedding
  sentence_scores = np.sum(similarity_matrix, axis=1)# Calculate sentence scores (e.g., sum of similarity to all other sentences)
  ranked_sentence_indices =np.argsort(sentence_scores)[::-1]
  top_sentence_indices =sorted(ranked_sentence_indices[:num_sentences])

  summary = [sentences[i] for i in top_sentence_indices]
  return " ".join(summary)

selected_products['BERT_Summary']= selected_products['reviewText'].apply(BertSummarizer)

selected_products.head(5)
#selected_products.to_csv("LLM_Model_Summaries_for_Diff_models.csv")

pd.to_csv("LLM_Model_Summaries_for_Diff_models.csv")

"""#Product Feature Extration for Business Strategy"""

from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd

selected_products['cleaned_reviewText'] = selected_products['cleaned_reviewText'].fillna("") #handles empty rows

grouped_reviews = selected_products.groupby('asin')['reviewText'].apply(lambda x: ' '.join(x.tolist())) #group reviews under unique product

tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words ='english')
tfidf_matrix = tfidf_vectorizer.fit_transform(grouped_reviews)

feature_names = tfidf_vectorizer.get_feature_names_out() #get feature names
tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), index=grouped_reviews.index, columns = feature_names) #create a datafram for TFIDF scores

def get_top_features(row, n=10):
  top_features = row.sort_values(ascending=False).head(n).index.tolist()
  return top_features #display ten most common features

#apply the function to get top features for each product
top_product_features = tfidf_df.apply(get_top_features, axis=1).to_dict()
print("top features identified for the first few products:")
for asin, features in list(top_product_features.items())[:6]:
  print(f"Product {asin}: {features}")

"""#Extract product features and the sentences that is used by customers to describe it."""

def extract_sentences_with_features(reviews_df, product_features):
    """
    Extracts sentences from reviews that contain any of the product's key features.
    """
    feature_sentences = {} #create empty dict
    for asin, features in product_features.items(): #loop thru id and features
        feature_sentences[asin] = {} #create empty dict for the id for a nested dict
        product_reviews = selected_products[selected_products['asin'] == asin]['reviewText'].dropna().tolist() #Creates a boolean filter selecting only rows where the asin column matches the given product ID.

        for feature in features: #loop thru the features
            feature_sentences[asin][feature] = [] #This line initializes an empty list for a specific product (asin) and a specific feature inside a nested dictionary.
            for review in product_reviews:
                sentences = nltk.sent_tokenize(review)
                for sentence in sentences:
                    # Simple check if feature (as a word or phrase) is in the sentence
                    if feature.lower() in sentence.lower():
                        feature_sentences[asin][feature].append(sentence) #tokenize each sentene
    return feature_sentences

# Extract sentences containing the identified top features
sentences_with_features = extract_sentences_with_features(selected_products, top_product_features)

# Print extracted sentences for the first few products and their features as an example
print("Extracted sentences for the first few products and their features:")
for asin, features in list(sentences_with_features.items())[:2]: #convert asin and feature to list then slice
    print(f"Product {asin}:")
    for feature, sentences in features.items(): #loop thru the sentence and features
        print(f"  Feature '{feature}':") #print the feature in the sentence
        for i, sent in enumerate(sentences[:3]): # Print up to 3 sentences per feature
            print(f"    - {sent}")
        if len(sentences) > 3:
             print(f"    ... and {len(sentences) - 3} more sentences.") #print the length of the sentence

"""Customers used terms to describe their experience of the product they purchased based on the features associated with these product. understanding their sentiment will provide avenue to make the product better to increase sales by some percentage. In the next block we will calculate average of the terms used to describe the featuers by customers where values close to 1 shows positive sentiment while values closer to zero is the opposite.

# Product Feature Sentiment Analysis Results

Below are the key features identified for each sampled product, along with the aggregated sentiment associated with mentions of that feature in the reviews.

* **Positive Sentiment:** Indicates that the feature is generally discussed favorably in the reviews.
* **Neutral Sentiment:** Suggests that mentions of the feature are neither strongly positive nor negative.
* **Negative Sentiment:** Indicates that the feature is generally discussed unfavorably in the reviews.

Let's look at the results for a few products:
"""

from nltk.sentiment.vader import SentimentIntensityAnalyzer
import statistics

# Assuming sid (SentimentIntensityAnalyzer) is already initialized from a previous cell
# If not, initialize it here:
import nltk
nltk.download('vader_lexicon')
sid = SentimentIntensityAnalyzer() #initialize analyzer

def analyze_feature_sentiment(feature_sentences_dict):
    """
    Analyzes the sentiment of sentences for each feature and aggregates it.
    """
    feature_sentiment = {} #empty dictionary
    for asin, features in feature_sentences_dict.items(): #loop id and features in dict
        feature_sentiment[asin] = {} #creates an empty dictionary for a specific product (identified by asin) inside the feature_sentiment dictionary.
        for feature, sentences in features.items(): #loop thru features and sentences
            sentiments = [sid.polarity_scores(sent)['compound'] for sent in sentences if sent.strip()] # Analyze sentiment for non-empty sentences
            if sentiments:
                # Aggregate sentiment (e.g., using mean)
                average_sentiment = statistics.mean(sentiments)
                # You can categorize sentiment here (e.g., >0.05 positive, <-0.05 negative, else neutral)
                if average_sentiment > 0.05:
                    sentiment_category = "Positive"
                elif average_sentiment < -0.05:
                    sentiment_category = "Negative"
                else:
                    sentiment_category = "Neutral"

                feature_sentiment[asin][feature] = {
                    "average_sentiment": average_sentiment,
                    "sentiment_category": sentiment_category,
                    "sentence_count": len(sentiments) # Count of sentences with sentiment analyzed
                }
            else:
                # Handle cases where no sentences were found for a feature (shouldn't happen if feature extraction worked)
                 feature_sentiment[asin][feature] = {
                    "average_sentiment": None,
                    "sentiment_category": "No sentences found",
                    "sentence_count": 0
                 }

    return feature_sentiment

# Analyze sentiment for the extracted sentences
product_feature_sentiment = analyze_feature_sentiment(sentences_with_features)

# Print aggregated sentiment for the first few products and their features as an example
print("Aggregated sentiment for the first few products and their features:")
for asin, features in list(product_feature_sentiment.items())[:2]: #returns all products and their feature-sentiment dictionaries and convert it into a list so we can slice it
    print(f"Product {asin}:")
    for feature, sentiment_info in features.items():
        print(f"  Feature '{feature}': {sentiment_info['sentiment_category']} (Average Sentiment: {sentiment_info['average_sentiment']:.2f}, Sentences: {sentiment_info['sentence_count']})")

"""As mentioned above, values closer to 1 indicates positive sentiment while values closer to zero indicate the opposite and values of zero are neutral. These values calculated for each feature can be used to calculate sale projection for each product. Thus, in the next block we will calculate percentage sale increases or decreases relative to the project features."""

num_products_to_dispaly = 5

for i, (asin, features) in enumerate(list(product_feature_sentiment.items())[:num_products_to_dispaly]): #loop thru product ID, features in the product_feature_sentiment list
  print(f"\nProduct ASIN: {asin}")
  for feature, sentiment_info in features.items(): #loop thru feature, sentiment infor
    if sentiment_info['average_sentiment'] is not None: #if value not zero
      average_sentiment_str = f"{sentiment_info['average_sentiment']:.2f}"
    else:
      average_sentiment_str = "N/A"
    print(f"  - Feature '{feature}': {sentiment_info['sentiment_category']} (Average Sentiment: {average_sentiment_str}, Sentences: {sentiment_info['sentence_count']})")

  else:
    print("no features found for this product.")

"""As mentioned above, values closer to 1 indicates positive sentiment while values closer to zero indicate the opposite and values of zero are neutral. These values calculated for each feature can be used to calculate sale projection for each product. Thus, in the next block we will calculate percentage sale increases or decreases relative to the project features."""

def suggest_feature_improvements_priority(feature_sentiment_dict, base_sales_dict, target_increase_pct=10, max_increase_pct=20):
    """
    Suggestions for features to improve with a priority score based on sentiment.

    Args:
        feature_sentiment_dict: output of analyze_feature_sentiment (average_sentiment per feature)
        base_sales_dict: dict {asin: current_sales} representing current sales numbers
        target_increase_pct: the desired overall sales increase (percentage)
        max_increase_pct: maximum possible sales increase per highly positive feature sentiment

    Returns:
        dict: {asin: {"estimated_sales": float, "features_to_improve": list of (feature, priority)}}
    """
    suggestions = {} #create a dictionary to store

    for asin, features in feature_sentiment_dict.items(): #loop thru id, features dictionary
        base_sales = base_sales_dict.get(asin, 100)  # default 100 if not provided
        current_factor = 0

        feature_priorities = [] #create a container

        for feature, info in features.items(): #loop thru the features and product info
            avg_sent = info.get("average_sentiment")

            if avg_sent is not None:
                # Calculate sales adjustment factor
                if avg_sent > 0:
                    adjustment = (avg_sent / 1.0) * max_increase_pct #calculate percentage increase relative to average sentiment
                elif avg_sent < 0:
                    adjustment = (avg_sent / -1.0) * (-max_increase_pct) #calculate percentage decrease relative to average sentiment
                else:
                    adjustment = 0 #neutral sentiment or avg = 0
                current_factor += adjustment

                # Compute priority: more negative sentiment = higher priority (closer to 1)
                priority = max(0, min(1, -avg_sent))  # negative sentiment -> 0..1
                if avg_sent <= 0:  # only consider features to improve
                    feature_priorities.append((feature, priority)) #append priority and features

        # Sort features by descending priority (worst sentiment first)
        feature_priorities.sort(key=lambda x: x[1], reverse=True)

        # Calculate estimated sales
        estimated_sales = base_sales * (1 + current_factor / 100)

        suggestions[asin] = {
            "estimated_sales": estimated_sales,
            "features_to_improve": feature_priorities
        }

    return suggestions

target_increase = 15  # target 15% sales increase
base_sales = {asin: 100 for asin in product_feature_sentiment.keys()} #assign a default value of 100 as the base-sale value. this can be change with the actual is available

feature_improvement_suggestions = suggest_feature_improvements_priority(
    product_feature_sentiment, base_sales, target_increase_pct=target_increase
)

for asin, info in feature_improvement_suggestions.items():  #loopthru the product id, information
    print(f"Product {asin}:") #product ID
    print(f"  Estimated sales: {info['estimated_sales']:.0f}") #
    if info['features_to_improve']: #features with negative sentiment
        print("  Features to improve (priority 0-1):") #score the priority
        for feat, prio in info['features_to_improve']:
            print(f"    {feat}: {prio:.2f}") #print product feature and priority score pair
    else:
        print("  Already meeting target sales increase!")

"""The result above shows a list of the 100 selected product with their estimated sales (i.e. price sold) relative to the customer sentiment. In order words, the terms used to described the features of the product are ranked using "priority" score. The closer to 1 the priority is, the more iimportant it is to improve that feature in order to increase sales. Features with priority score of 0 shows that they are well received by the customers.

Additionally, product which are tagged "Already meeting target sales increase" have sales increased by 40-100% and the priority is zero.
"""

def strip_html_urls(text: str) -> str:
    # Remove HTML tags like <br>, <div>, <p>
    text = re.sub(r"<[^>]+>", " ", text)
    # Remove URLs (http links or www links)
    text = re.sub(r"http\S+|www\.\S+", " ", text)
    # Collapse multiple spaces into a single space and trim ends
    return re.sub(r"\s+", " ", text).strip()

def _tok(t) -> list[str]:
    # Convert None to empty string, otherwise ensure it's a string
    t = "" if t is None else str(t)
    # Normalize text: lowercase + remove HTML and URLs
    t = strip_html_urls(t.lower())
    # Remove non-alphanumeric characters, split into words,
    # and keep only tokens longer than 2 characters
    return [w for w in re.sub(r"[^a-z0-9\s]", " ", t).split() if len(w) > 2]

def _ngrams(words, n):
    # Generate n-grams (e.g., 1-grams, 2-grams, etc.)
    return [tuple(words[i:i+n]) for i in range(len(words)-n+1)]

def rouge_n(summary: str, reference: str, n: int = 1):
    # Tokenize summary and reference text
    s = _tok(summary); r = _tok(reference)
    # Count n-grams in each
    s_ngr = Counter(_ngrams(s, n)); r_ngr = Counter(_ngrams(r, n))
    # Compute overlapping n-grams
    overlap = sum((s_ngr & r_ngr).values())
    # Total n-grams in reference and summary (avoid division by zero)
    r_tot = max(sum(r_ngr.values()), 1); s_tot = max(sum(s_ngr.values()), 1)
    # ROUGE precision = overlap / summary total
    rec = overlap / r_tot
    # ROUGE recall = overlap / reference total
    prec = overlap / s_tot
    # F1 score = harmonic mean of precision and recall
    f1 = 0 if prec+rec==0 else 2*prec*rec/(prec+rec)
    # Return dictionary of metrics
    return {"precision":prec, "recall":rec, "f1":f1}

def rouge_l(summary: str, reference: str):
    # Tokenize summary and reference
    s = _tok(summary); r = _tok(reference)
    # Dynamic programming table to compute LCS (Longest Common Subsequence)
    dp = [[0]*(len(r)+1) for _ in range(len(s)+1)]
    # Fill table: classic LCS algorithm
    for i in range(1,len(s)+1):
        for j in range(1,len(r)+1):
            dp[i][j] = dp[i-1][j-1]+1 if s[i-1]==r[j-1] else max(dp[i-1][j], dp[i][j-1])
    # LCS length
    lcs = dp[-1][-1]
    # ROUGE-L recall and precision
    rec = lcs/max(len(r),1)
    prec = lcs/max(len(s),1)
    # Compute F1
    f1 = 0 if prec+rec==0 else 2*prec*rec/(prec+rec)
    # Return ROUGE-L scores
    return {"precision":prec, "recall":rec, "f1":f1}

# Convert list of selected sentences into a single string for comparison
freq_summary_text  = " ".join(sum_freq)
tfidf_summary_text = " ".join(sum_tfidf)

# Convert lists of selected sentences into single strings for evaluation
freq_summary_text  = " ".join(sum_freq)
tfidf_summary_text = " ".join(sum_tfidf)

freq_summary_text

# Print ROUGE scores for both summarization strategies
print({
    "Frequency": {
        "ROUGE-1": rouge_n(freq_summary_text, reference_text, 1),   # unigram overlap
        "ROUGE-2": rouge_n(freq_summary_text, reference_text, 2),   # bigram overlap
        "ROUGE-L": rouge_l(freq_summary_text, reference_text),      # longest common subsequence
    },
    "TFIDF+MMR": {
        "ROUGE-1": rouge_n(tfidf_summary_text, reference_text, 1),
        "ROUGE-2": rouge_n(tfidf_summary_text, reference_text, 2),
        "ROUGE-L": rouge_l(tfidf_summary_text, reference_text),
    }
})

!pip install gradio
import gradio as gr

# Import the pandas library for loading and manipulating CSV data
import pandas as pd

# Define a simple function to display the first 5 rows of a CSV as a preview
def DisplayData():
  df = pd.read_csv('/content/sample_data/LLM_Model_Summaries_for_Diff_models.csv')  # Load CSV file
  return df.head(5)  # Return the first 5 rows


# Function to filter the DataFrame by product ID
def filtered_data(Product):
  if Product != 'ALL':              # If an actual ID is selected instead of 'ALL'
    filtered_df = df[df['asin'] == Product]   # Filter rows where asin matches the selection
  return filtered_df               # Return the filtered dataset


# --- Gradio UI Construction ---
with gr.Blocks() as demo:
  with gr.Row():  # Group UI components in a row
    Product_dropdown = gr.Dropdown(
        choices=df['asin'].unique().tolist(),  # All available product IDs
        value='ALL',                           # Default selection
        label='Filter by Product'
    )

  # Output table to display data
  output_df = gr.DataFrame(value=df)

  # Update displayed data when dropdown changes
  Product_dropdown.change(
      fn=filtered_data,        # Function to run
      inputs=Product_dropdown, # Input passed to function
      outputs=output_df        # UI component to update
  )

# Launch Gradio app
demo.launch()




# Mount Google Drive for access to files
from google.colab import drive
drive.mount('/content/drive')


# Import needed libraries
import gradio as gr
import pandas as pd
import numpy as np

# --- Load CSV File ---
df = pd.read_csv('/content/sample_data/LLM_Model_Summaries_for_Diff_models.csv')

# --- Helper Functions for UI ---

def get_unique_ids():
    """Create dropdown list of IDs including 'All'."""
    unique_ids = sorted(df['asin'].unique().tolist())   # Unique product IDs
    return ['All'] + unique_ids                         # Add 'All' option

def get_summarization_model():
    """Dropdown list of available summary model column names."""
    return ['All'] + ['TextRankSummary','T5_product_summary','Pegasus_summary','BERT_Summary']


# Main filtering function used by Gradio UI
def filter_data(selected_id, selected_summary_col):
    """
    Filters DataFrame depending on dropdown choices.
    Handles:
      - Showing all products
      - Showing one product pivoted
      - Showing selected summary column
    """

    # Columns that ALWAYS appear when single-product pivot is displayed
    core_columns = ['asin', 'reviewText']

    # Case 1: A specific ID + specific summary column selected
    if (selected_id != 'All') & (selected_summary_col != 'All'):
        # Get only the selected row + selected summary column
        selected_row = df[df['asin'] == selected_id][core_columns + [selected_summary_col]].squeeze()

        # Convert Series into pivot-style two-column table
        pivoted_df = selected_row.reset_index()
        pivoted_df.columns = ['Attribute', 'Value']
        return pivoted_df

    # Case 2: Only specific ID selected (no summary column filter)
    elif selected_id != 'All':
        selected_row = df[df['asin'] == selected_id].squeeze()
        pivoted_df = selected_row.reset_index()
        pivoted_df.columns = ['Attribute', 'Value']
        return pivoted_df

    # Case 3: 'All' selected → show entire dataset
    else:
        return df


# --- Gradio App UI Layout ---
with gr.Blocks(title="CSV Data Viewer") as demo:
    gr.Markdown("# CSV Data Viewer")
    gr.Markdown("View product details or choose summarization method.")

    with gr.Row():
        # Dropdown for product ID
        id_dropdown = gr.Dropdown(
            choices=get_unique_ids(),
            label="Select ID",
            value='All'
        )

        # Dropdown for choosing which summary model column to show
        summary_dropdown = gr.Dropdown(
            choices=get_summarization_model(),
            label="Select Summary Column",
            value='All'
        )

    # Table for output display
    output_df = gr.Dataframe(
        value=filter_data('All', 'All'),  # Initial table
        interactive=False,
        label="Filtered Data"
    )

    # Event: update table when product ID is changed
    id_dropdown.change(
        fn=filter_data,
        inputs=[id_dropdown, summary_dropdown],
        outputs=output_df
    )

    # Event: update table when summary column is changed
    summary_dropdown.change(
        fn=filter_data,
        inputs=[id_dropdown, summary_dropdown],
        outputs=output_df
    )


# Launch Gradio app when script is run
if __name__ == "__main__":
    demo.launch()

"""Future work/enhancements:

* Extend the current project to utilize **web scraping** to check against the Amazon current reviews and compare against the summary generated by Model for fine tuning the model

* Utilize Machine learning models to apply Topic modeling and using that to clean the out of place reviews from the dataset. For example removing "books" related reviews from the "Beauty" category products

* Dataset does have a column indicating whether a review is from a verified purchase or not. Utilize this feature to further enhance the summarization of reviews based on **verified purchases**.

* Unverified purchases may be spam reviews or bot reviews to promote a product which doesn't add true value to the reviews or sentiment. Model can be further enhanced to detect **fake reviews**

* Even with verified purchases, length or duration of product used by reviewer matters. A product may have gotten a very positive review during initial few days

* Time series Analysis can be employed to analyze the Product sentiment or quality based on duration the product used by reviewer(s)

* Model can be further enhanced to check the quality of the product build over the time. A Product may have great initial build quality but due to some circumstances the product quality may change, by employing this type of analysis the manufacturers can track the Product reviews and focus on fixing those to enhance customer satisfaction
"""

